{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T16:24:14.167095Z",
     "start_time": "2020-11-08T16:24:14.154194Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from unicodedata import normalize\n",
    "import html\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T16:24:14.601317Z",
     "start_time": "2020-11-08T16:24:14.182737Z"
    }
   },
   "outputs": [],
   "source": [
    "data_articles_raw = pickle.load(open(\"../DATA/artists_articles_raw.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract article parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T16:24:19.432521Z",
     "start_time": "2020-11-08T16:24:14.602669Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4400f702e17c4ec2a02b7bc5d43ab53a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=26807), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def extract_text_and_title(data: list):\n",
    "\n",
    "    '''This function extracts the article itself and the title of it'''\n",
    "    \n",
    "    data_artists = list()\n",
    "    \n",
    "    title_pattern = r'<title>[\\s\\S]*?</title>'\n",
    "    full_text_pattern = r'<text[\\s\\S]*?>[\\s\\S]*?</text>'\n",
    "    text_pattern = r'<text[\\s\\S]*?>'\n",
    "    \n",
    "    with tqdm(total=len(data)) as pbar:\n",
    "        \n",
    "        for d in data:\n",
    "            data_artist = dict()\n",
    "            data_artist['articulo_raw'] = d\n",
    "            \n",
    "            data_artist['id_titulo'] = re.search(title_pattern, d).group()[7:-8]\n",
    "            \n",
    "            full_texto = re.search(full_text_pattern, d).group()\n",
    "            text_header = re.search(text_pattern, full_texto).group()\n",
    "            data_artist['texto_raw'] = full_texto.split(text_header)[1]\n",
    "                      \n",
    "            data_artists.append(data_artist)\n",
    "            pbar.update(1)\n",
    "        \n",
    "    return data_artists\n",
    "\n",
    "data_artists = extract_text_and_title(data_articles_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T16:24:19.635359Z",
     "start_time": "2020-11-08T16:24:19.434248Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23379d2de77a4178ab9c2b078c6cc822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=26807), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def clean_text(data: list):\n",
    "   \n",
    "    '''This function cleans slightly the text of the articles'''\n",
    "    \n",
    "    with tqdm(total=len(data)) as pbar:    \n",
    "        for d in data:\n",
    "            d['texto_raw'] = d['texto_raw'].split('</text>')[0]\n",
    "            pbar.update(1)\n",
    "            \n",
    "    return data\n",
    "    \n",
    "data_artists = clean_text(data_artists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean particular cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T16:24:19.699612Z",
     "start_time": "2020-11-08T16:24:19.636800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff464227ab1462b8a08ede8ce96d4db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=26807), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with tqdm(total=len(data_artists)) as pbar:\n",
    "    for d in data_artists:\n",
    "        if d['id_titulo']=='Daniela Carpio':\n",
    "            d['texto_raw'] = (d['texto_raw']\n",
    "                              .replace('{{{{','{{'))\n",
    "\n",
    "        elif d['id_titulo']=='Ski Mask the Slump God':\n",
    "            d['texto_raw'] = (d['texto_raw']\n",
    "                              .replace('* escritor de canciones', '* escritor de canciones}}'))\n",
    "\n",
    "        elif d['id_titulo']=='Marcus &amp; Martinus':\n",
    "            d['texto_raw'] = (d['texto_raw']\n",
    "                              .replace('marcusandmartinus.com/', 'marcusandmartinus.com/]]'))\n",
    "\n",
    "        elif d['id_titulo']=='Virgil Popa':\n",
    "            d['texto_raw'] = (d['texto_raw']\n",
    "                              .replace('Virgil Popa.jpg', 'Virgil Popa.jpg}}'))\n",
    "\n",
    "        elif d['id_titulo']=='Rangel':\n",
    "            d['texto_raw'] = (d['texto_raw']\n",
    "                              .replace('= [[elcartelurbano]],', '= [[elcartelurbano]]}}'))\n",
    "\n",
    "        elif d['id_titulo']=='Jennifer Holliday':\n",
    "            d['texto_raw'] = (d['texto_raw']\n",
    "                              .replace('10|1960|edad', '10|1960|edad}}'))\n",
    "\n",
    "        elif d['id_titulo']=='Infinite (grupo musical)':\n",
    "            d['texto_raw'] = (d['texto_raw']\n",
    "                              .replace('[[Hoya (Cantante)|Hoya]]', '[[Hoya (Cantante)|Hoya]]}}'))\n",
    "\n",
    "        elif d['id_titulo']=='Coro de la Generalidad Valenciana':\n",
    "            d['texto_raw'] = (d['texto_raw']\n",
    "                              .replace('[[Francisco Hervás]]&lt;br /&gt;', '[[Francisco Hervás]]&lt;br /&gt;}}'))\n",
    "\n",
    "        elif d['id_titulo']=='Boddega':\n",
    "            d['texto_raw'] = (d['texto_raw']\n",
    "                              .replace('Roberto Jijón, Carlos del Campo', 'Roberto Jijón, Carlos del Campo}}'))\n",
    "\n",
    "        elif d['id_titulo']=='Andrea Bocelli':\n",
    "            d['texto_raw'] = (d['texto_raw']\n",
    "                              .replace('|idioma=español{{', '|idioma=español}}'))\n",
    "            \n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove particular cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T16:24:19.758044Z",
     "start_time": "2020-11-08T16:24:19.700825Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "385fa2971f2342949702f354a344ab2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=26807), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def remove_particular_cases(data, to_remove_l):\n",
    "    \n",
    "    ind_to_remove_l = list()\n",
    "    \n",
    "    with tqdm(total=len(data)) as pbar:\n",
    "        for ind, d in enumerate(data):\n",
    "            if d['id_titulo'] in to_remove_l:\n",
    "                ind_to_remove_l.append(ind)\n",
    "                \n",
    "            pbar.update(1)\n",
    "\n",
    "    for ind in ind_to_remove_l[::-1]:\n",
    "        data.pop(ind)\n",
    "        \n",
    "      \n",
    "    return data\n",
    "\n",
    "\n",
    "titulos_to_remove = ['Wikipedia:Tablón de anuncios de los bibliotecarios/Portal/Archivo/Protección de artículos/2018/04',\n",
    "                     'Plantilla:Ficha de persona/doc',\n",
    "                     'Wikipedia:Café/Portal/Archivo/Propuestas/2009/09',\n",
    "                     'Wikipedia:Consultas de borrado/Giancarlo Monsalve',\n",
    "                     'Gauvain Sers',\n",
    "                     'Wernher von Braun',\n",
    "                     'Raymond Kurzweil',\n",
    "                     'Tomás Luis de Victoria',\n",
    "                     'Cristóbal de Morales',\n",
    "                     'Francisco Guerrero', \n",
    "                     'Juan Cabanilles',\n",
    "                     'Robert Moog',\n",
    "                     'Diego Ortiz',\n",
    "                     'Alejandro García Villalón («Virulo»)',\n",
    "                     'Jean-Pierre Christin',\n",
    "                     'Juan Navarro Hispalensis',\n",
    "                     'Keiji Fujiwara',\n",
    "                     'Phil Zimmermann']\n",
    "\n",
    "data_artists = remove_particular_cases(data_artists, titulos_to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode HTML tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T16:24:21.831540Z",
     "start_time": "2020-11-08T16:24:19.759246Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "619ed72454954084af17a3385f6b6331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=26789), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def decode_html_tags(data: list, key_name: str, new_key_name: str):\n",
    "\n",
    "    '''This function decodes HTML tags from each article:     &lt;ref&gt;   -->  <ref> '''\n",
    "    \n",
    "    with tqdm(total=len(data)) as pbar:\n",
    "        \n",
    "        for d in data:\n",
    "            d[new_key_name] = html.unescape(d[key_name])\n",
    "            pbar.update(1)\n",
    "        \n",
    "    return data\n",
    "\n",
    "data_artists = decode_html_tags(data_artists, 'texto_raw', 'texto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract hidden elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract bracket structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T16:24:30.868262Z",
     "start_time": "2020-11-08T16:24:21.832968Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e87827c38686445588e1f21219c44b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=26789), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def extract_bracket_structure(data: list, key_name: str, new_key_name: str):\n",
    "   \n",
    "    '''This function extracts all the references from each article'''\n",
    "    \n",
    "    with tqdm(total=len(data)) as pbar:\n",
    "        for d in data:\n",
    "            \n",
    "            brackets_l = list()\n",
    "            texto_processed = d[key_name]\n",
    "    \n",
    "            left_index = 0\n",
    "            right_index = len(texto_processed)\n",
    "    \n",
    "            list_index = 0\n",
    "            while True:\n",
    "        \n",
    "                reg_resp_l = re.search(r'{{', texto_processed[left_index:right_index])\n",
    "\n",
    "                if reg_resp_l == None:\n",
    "                    break\n",
    "            \n",
    "                else:\n",
    "            \n",
    "                    left_index = reg_resp_l.span()[0] + left_index\n",
    "                    reg_resp_r = re.search(r'}}', texto_processed[left_index:right_index])\n",
    "\n",
    "                    if reg_resp_r == None:\n",
    "                        break\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        right_index = reg_resp_r.span()[1] + left_index\n",
    "                        reg_resp_l_2 = re.search(r'{{', texto_processed[left_index+2:right_index])\n",
    "\n",
    "                        if reg_resp_l_2 == None:\n",
    "                            bracket = re.search(r'{{[\\s\\S}]*?}}', texto_processed[left_index:]).group(0)\n",
    "                            list_index_str = '%{% '+ str(list_index) + ' %}%'\n",
    "                            texto_processed = list_index_str.join(texto_processed.split(bracket))\n",
    "\n",
    "                            brackets_l.append(bracket)\n",
    "                            list_index += 1\n",
    "\n",
    "                            left_index = 0\n",
    "                            right_index = len(texto_processed)\n",
    "\n",
    "                        else:\n",
    "                            left_index = reg_resp_l_2.span()[0] + left_index\n",
    "                \n",
    "                \n",
    "            d[new_key_name] = texto_processed\n",
    "            d['_brackets_'] = brackets_l\n",
    "\n",
    "            pbar.update(1)\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "data_artists = extract_bracket_structure(data_artists, 'texto', 'texto')       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract infobox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T16:24:31.228962Z",
     "start_time": "2020-11-08T16:24:30.870257Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f642aab5679449c7a91e96b0279ffc37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=26789), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def extract_infobox(data: list):\n",
    "    \n",
    "    ''' This function extracts the infobox part of the articles'''\n",
    "    \n",
    "    pattern = r'{{Ficha de'\n",
    "    pattern_persona = r'{{Ficha de persona'\n",
    "\n",
    "    with tqdm(total=len(data)) as pbar:\n",
    "        for d in data:\n",
    "            for b in d['_brackets_']:\n",
    "                response = re.match(pattern, b)\n",
    "                if response:\n",
    "                    d['infobox'] = b\n",
    "                    \n",
    "                    response_persona = re.match(pattern_persona, b)\n",
    "                    if response_persona:\n",
    "                        d['tipo_articulo'] = 'persona'\n",
    "                    else:\n",
    "                        d['tipo_articulo'] = 'grupo' \n",
    "                    \n",
    "                    \n",
    "            pbar.update(1)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "data_artists = extract_infobox(data_artists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T16:24:36.732408Z",
     "start_time": "2020-11-08T16:24:31.231044Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9323ead68fd44dd995b0150513373c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=26789), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3777b248fd94b50be2ab1e42cc8a1ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=26789), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def extract_references(data: list, key_name: str, new_key_name: str):\n",
    "   \n",
    "    '''This function extracts all the references from each article'''\n",
    "    \n",
    "    with tqdm(total=len(data)) as pbar:\n",
    "        for d in data:\n",
    "            \n",
    "            references_l = list()\n",
    "            texto_processed = d[key_name]\n",
    "    \n",
    "            left_index = 0\n",
    "            right_index = len(texto_processed)\n",
    "    \n",
    "            list_index = 0\n",
    "            while True:\n",
    "                \n",
    "                reg_resp_l = re.search(r'<[^/!]*?>', texto_processed[left_index:right_index])\n",
    "                if reg_resp_l == None:\n",
    "                    \n",
    "                    reg_resp_l = re.search(r'<![\\s\\S]*?>', texto_processed[left_index:right_index])        \n",
    "                    if reg_resp_l != None:\n",
    "                    \n",
    "                        texto_processed = ''.join(texto_processed.split(reg_resp_l.group()))\n",
    "                       \n",
    "                    else:\n",
    "                        \n",
    "                        reg_resp_l = re.search(r'<[^/]*?/>', texto_processed[left_index:right_index])\n",
    "                        if reg_resp_l == None:\n",
    "                            \n",
    "                            break\n",
    "                        \n",
    "                        else:\n",
    "\n",
    "                            tag_raw = reg_resp_l.group()\n",
    "                            tag_name = tag_raw.split(' ')[0][1:]\n",
    "\n",
    "                            try:\n",
    "                                tag_value = tag_raw.split(' ')[1][:-2]\n",
    "                            except:\n",
    "                                tag_value = ''\n",
    "\n",
    "                            tag = dict()\n",
    "                            tag = {'tag': tag_name, 'value': tag_value}\n",
    "\n",
    "                            list_index_str = '%«% '+ str(list_index) + ' %»%'\n",
    "                            list_index += 1\n",
    "                            \n",
    "                            texto_processed = list_index_str.join(texto_processed.split(tag_raw))\n",
    "                            \n",
    "                            references_l.append(tag)\n",
    " \n",
    "                            left_index = 0\n",
    "                            right_index = len(texto_processed)\n",
    "                        \n",
    "                \n",
    "                else:\n",
    "                    \n",
    "                    tag_name = reg_resp_l.group()[1:-1].split(' ')[0]\n",
    "                    tag_raw_open = reg_resp_l.group()\n",
    "                    \n",
    "                    left_index = reg_resp_l.span()[1] + left_index\n",
    "                    \n",
    "                    reg_resp_r = re.search(r'</[\\s\\S]*?>', texto_processed[left_index:right_index])\n",
    "                    if reg_resp_r == None:\n",
    "                        \n",
    "                        break\n",
    "\n",
    "                        \n",
    "                    else:\n",
    "                        \n",
    "                        tag_raw_close = reg_resp_r.group()\n",
    "                        right_index = reg_resp_r.span()[0] + left_index\n",
    "\n",
    "                        reg_resp_l_2 = re.search(r'<[\\s\\S]*?>', texto_processed[left_index:right_index-1])\n",
    "                        if reg_resp_l_2 == None:\n",
    "                            \n",
    "                            tag_value = texto_processed[left_index:right_index]\n",
    "                            tag_raw = tag_raw_open + tag_value + tag_raw_close\n",
    "                            tag = {'tag': tag_name, 'value': tag_value}\n",
    "\n",
    "                            list_index_str = '%«% '+ str(list_index) + ' %»%'\n",
    "                            list_index += 1\n",
    "\n",
    "                            texto_processed = list_index_str.join(texto_processed.split(tag_raw))\n",
    "\n",
    "                            references_l.append(tag)\n",
    "\n",
    "                            left_index = 0\n",
    "                            right_index = len(texto_processed)\n",
    "\n",
    "                        else:\n",
    "                                  \n",
    "                            left_index = reg_resp_l_2.span()[0] + left_index\n",
    "                \n",
    "                \n",
    "            d[new_key_name] = texto_processed\n",
    "            d['_references_' + new_key_name] = references_l\n",
    "\n",
    "            pbar.update(1)\n",
    "        \n",
    "    return data\n",
    "\n",
    "data_artists = extract_references(data_artists, 'texto', 'texto')  \n",
    "data_artists = extract_references(data_artists, 'infobox', 'infobox')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace note separator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T16:24:37.987919Z",
     "start_time": "2020-11-08T16:24:36.734012Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3028b9b91705451c9efa9c7ecd3df4ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=26789), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def replace_note_separator(data: list, key_name: str, new_key_name: str):\n",
    "   \n",
    "    '''This function replaces note separators'''\n",
    "    \n",
    "    with tqdm(total=len(data)) as pbar:\n",
    "        \n",
    "        for ind,d in enumerate(data):    \n",
    "            texto_processed = d[key_name]\n",
    "    \n",
    "            left_index = 0\n",
    "            right_index = len(texto_processed)\n",
    "    \n",
    "            while True:\n",
    "                \n",
    "                reg_resp_l = re.search(r'\\[\\[', texto_processed[left_index:right_index])\n",
    "\n",
    "                if reg_resp_l == None:\n",
    "                    break\n",
    "            \n",
    "                else:\n",
    "            \n",
    "                    left_index = reg_resp_l.span()[0] + left_index\n",
    "                    reg_resp_r = re.search(r'\\]\\]', texto_processed[left_index:right_index])\n",
    "\n",
    "                    if reg_resp_r == None:\n",
    "                        print('¡warning!')\n",
    "                        print(ind)\n",
    "                        break\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        right_index = reg_resp_r.span()[1] + left_index\n",
    "                        note = texto_processed[left_index:right_index]\n",
    "                        note_replacement = note.replace('|', '%%')\n",
    "                        \n",
    "                        texto_processed = note_replacement.join(texto_processed.split(note))\n",
    "                        \n",
    "                        left_index = right_index\n",
    "                        right_index = len(texto_processed)\n",
    "                \n",
    "                \n",
    "            d[new_key_name] = texto_processed\n",
    "\n",
    "            pbar.update(1)\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "data_artists = replace_note_separator(data_artists, 'infobox', 'infobox')       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T16:24:39.824792Z",
     "start_time": "2020-11-08T16:24:37.989150Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(data_artists, open( \"../DATA/artists_articles.p\", \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
